{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 3559518494796711514\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 1447745945\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 15238993771098657187\n",
      "physical_device_desc: \"device: 0, name: Quadro M1000M, pci bus id: 0000:01:00.0, compute capability: 5.0\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_batch: <_VariantDataset shapes: (), types: tf.int32>\n",
      "X_batch: <_VariantDataset shapes: (), types: tf.int32>\n",
      "X_batch: <_VariantDataset shapes: (), types: tf.int32>\n",
      "X_batch: <_VariantDataset shapes: (), types: tf.int32>\n",
      "X_batch: <_VariantDataset shapes: (), types: tf.int32>\n",
      "X_batch: <_VariantDataset shapes: (), types: tf.int32>\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(123)\n",
    "tf.random.set_seed(123)\n",
    "\n",
    "n_steps=5\n",
    "dataset = tf.data.Dataset.from_tensor_slices(tf.range(16))\n",
    "dataset = dataset.window(n_steps, shift=2, drop_remainder=True)\n",
    "for idx, (X_batch) in enumerate(dataset):\n",
    "    print('X_batch:',X_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_batch: tf.Tensor([0 1 2 3 4], shape=(5,), dtype=int32)\n",
      "X_batch: tf.Tensor([2 3 4 5 6], shape=(5,), dtype=int32)\n",
      "X_batch: tf.Tensor([4 5 6 7 8], shape=(5,), dtype=int32)\n",
      "X_batch: tf.Tensor([ 6  7  8  9 10], shape=(5,), dtype=int32)\n",
      "X_batch: tf.Tensor([ 8  9 10 11 12], shape=(5,), dtype=int32)\n",
      "X_batch: tf.Tensor([10 11 12 13 14], shape=(5,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.flat_map(lambda window: window.batch(n_steps))\n",
    "for idx, (X_batch) in enumerate(dataset):\n",
    "    print('X_batch:',X_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_batch: tf.Tensor(\n",
      "[[10 11 12 13]\n",
      " [ 2  3  4  5]\n",
      " [ 8  9 10 11]], shape=(3, 4), dtype=int32)\n",
      "y_batch: tf.Tensor(\n",
      "[[11 12 13 14]\n",
      " [ 3  4  5  6]\n",
      " [ 9 10 11 12]], shape=(3, 4), dtype=int32)\n",
      "X_batch: tf.Tensor(\n",
      "[[0 1 2 3]\n",
      " [4 5 6 7]\n",
      " [6 7 8 9]], shape=(3, 4), dtype=int32)\n",
      "y_batch: tf.Tensor(\n",
      "[[ 1  2  3  4]\n",
      " [ 5  6  7  8]\n",
      " [ 7  8  9 10]], shape=(3, 4), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.shuffle(10).map(lambda window: (window[:-1], window[1:]))\n",
    "dataset = dataset.batch(3).prefetch(1)\n",
    "for idx, (X_batch, y_batch) in enumerate(dataset):\n",
    "    print('X_batch:',X_batch)\n",
    "    print('y_batch:',y_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **CharRNN - Shakespeare_Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
      "1122304/1115394 [==============================] - 15s 13us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\user\\\\.keras\\\\datasets\\\\shakespeare.txt'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shakespeare_url = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n",
    "filepath = keras.utils.get_file('shakespeare.txt', shakespeare_url)\n",
    "filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(filepath) as f:\n",
    "    shakespeare_txt = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to \n"
     ]
    }
   ],
   "source": [
    "print(shakespeare_txt[:140])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n !$&',-.3:;?abcdefghijklmnopqrstuvwxyz\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(sorted(set(shakespeare_txt.lower())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = keras.preprocessing.text.Tokenizer(char_level=True)\n",
    "tokenizer.fit_on_texts(shakespeare_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[20, 6, 9, 8, 3]]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.texts_to_sequences(['first'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['f i r s t']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.sequences_to_texts([[20, 6, 9, 8, 3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ': 1,\n",
       " 'e': 2,\n",
       " 't': 3,\n",
       " 'o': 4,\n",
       " 'a': 5,\n",
       " 'i': 6,\n",
       " 'h': 7,\n",
       " 's': 8,\n",
       " 'r': 9,\n",
       " 'n': 10,\n",
       " '\\n': 11,\n",
       " 'l': 12,\n",
       " 'd': 13,\n",
       " 'u': 14,\n",
       " 'm': 15,\n",
       " 'y': 16,\n",
       " 'w': 17,\n",
       " ',': 18,\n",
       " 'c': 19,\n",
       " 'f': 20,\n",
       " 'g': 21,\n",
       " 'b': 22,\n",
       " 'p': 23,\n",
       " ':': 24,\n",
       " 'k': 25,\n",
       " 'v': 26,\n",
       " '.': 27,\n",
       " \"'\": 28,\n",
       " ';': 29,\n",
       " '?': 30,\n",
       " '!': 31,\n",
       " '-': 32,\n",
       " 'j': 33,\n",
       " 'q': 34,\n",
       " 'x': 35,\n",
       " 'z': 36,\n",
       " '3': 37,\n",
       " '&': 38,\n",
       " '$': 39}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_id = tokenizer.word_index\n",
    "max_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_id = len(max_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1115394"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_size = tokenizer.document_count\n",
    "dataset_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([19,  5,  8,  7,  2,  0, 18,  5,  2,  5, 35,  1,  9, 23, 10, 21,  1,\n",
       "       19,  3,  8,  1,  0, 16,  1,  0, 22,  8,  3, 18,  1,  1, 12,  0,  4,\n",
       "        9, 15,  0, 19, 13,  8,  2,  6,  1,  8, 17,  0,  6,  1,  4,  8,  0,\n",
       "       14,  1,  0,  7, 22,  1,  4, 24, 26, 10, 10,  4, 11, 11, 23, 10,  7,\n",
       "       22,  1,  4, 24, 17,  0,  7, 22,  1,  4, 24, 26, 10, 10, 19,  5,  8,\n",
       "        7,  2,  0, 18,  5,  2,  5, 35,  1,  9, 23, 10, 15,  3, 13])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[encoded] = np.array(tokenizer.texts_to_sequences([shakespeare_txt]))-1\n",
    "encoded[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167309\n"
     ]
    }
   ],
   "source": [
    "train_size = dataset_size*15//100\n",
    "print(train_size)\n",
    "dataset = tf.data.Dataset.from_tensor_slices(encoded[:train_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(19, shape=(), dtype=int32)\n",
      "tf.Tensor(5, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for x in dataset.take(2):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps=100\n",
    "windows_length=n_steps+1\n",
    "batch_size=32\n",
    "dataset = dataset.repeat().window(windows_length, shift=1, drop_remainder=True)\n",
    "dataset = dataset.flat_map(lambda window: window.batch(windows_length))\n",
    "dataset = dataset.map(lambda window: (window[:-1], window[1:])).shuffle(10000).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "X_batch: tf.Tensor(\n",
      "[[ 8  5 18 ... 14  5  2]\n",
      " [ 2  6  1 ... 12  5 12]\n",
      " [ 1  1  0 ...  1  0 19]\n",
      " ...\n",
      " [12 26  0 ... 13  0  4]\n",
      " [15  0 25 ...  3  0 21]\n",
      " [ 6  1  0 ...  1 11 22]], shape=(32, 100), dtype=int32)\n",
      "Y_batch: tf.Tensor(\n",
      "[[ 5 18  5 ...  5  2 15]\n",
      " [ 6  1  0 ...  5 12  0]\n",
      " [ 1  0 16 ...  0 19 11]\n",
      " ...\n",
      " [26  0  6 ...  0  4  8]\n",
      " [ 0 25  1 ...  0 21  8]\n",
      " [ 1  0  4 ... 11 22  7]], shape=(32, 100), dtype=int32)\n",
      "\n",
      "X_batch: tf.Tensor(\n",
      "[[ 3 16  0 ... 12  0  1]\n",
      " [ 5  9 24 ...  5 14  1]\n",
      " [ 2  5 35 ...  5  9  0]\n",
      " ...\n",
      " [ 7  1  9 ... 12  0  2]\n",
      " [ 0  1  4 ...  1  7  7]\n",
      " [ 0  5 14 ...  8 14  7]], shape=(32, 100), dtype=int32)\n",
      "Y_batch: tf.Tensor(\n",
      "[[16  0  5 ...  0  1  7]\n",
      " [ 9 24  0 ... 14  1  0]\n",
      " [ 5 35  1 ...  9  0  8]\n",
      " ...\n",
      " [ 1  9  4 ...  0  2  6]\n",
      " [ 1  4  2 ...  7  7  0]\n",
      " [ 5 14 22 ... 14  7 17]], shape=(32, 100), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for x,y in dataset.take(2):\n",
    "    print('\\nX_batch:',x)\n",
    "    print('Y_batch:',y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(lambda X_batch, y_batch: (tf.one_hot(X_batch, depth=max_id), y_batch))\n",
    "dataset = dataset.prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "X_batch: tf.Tensor(\n",
      "[[[0. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[1. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 1. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]], shape=(32, 100, 39), dtype=float32)\n",
      "Y_batch: tf.Tensor(\n",
      "[[ 0  8  1 ... 12  4  5]\n",
      " [16  6  3 ...  0  5  9]\n",
      " [15 17  0 ... 15  0  6]\n",
      " ...\n",
      " [23 10  5 ...  8  0  2]\n",
      " [10 16  3 ...  9 12  7]\n",
      " [12  4  9 ...  1  8  0]], shape=(32, 100), dtype=int32)\n",
      "(32, 100, 39) (32, 100)\n"
     ]
    }
   ],
   "source": [
    "for x,y in dataset.take(1):\n",
    "    print('\\nX_batch:',x)\n",
    "    print('Y_batch:',y)\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_9 (GRU)                  (None, None, 64)          20160     \n",
      "_________________________________________________________________\n",
      "time_distributed_8 (TimeDist (None, None, 39)          2535      \n",
      "=================================================================\n",
      "Total params: 22,695\n",
      "Trainable params: 22,695\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.GRU(64, return_sequences=True, input_shape=[None, max_id],\n",
    "                     dropout=0.2),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(max_id,\n",
    "                                                    activation=\"softmax\"))\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 5228 steps\n",
      "Epoch 1/2\n",
      "5228/5228 [==============================] - 184s 35ms/step - loss: 2.0332\n",
      "Epoch 2/2\n",
      "5228/5228 [==============================] - 170s 33ms/step - loss: 1.8139\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/device:GPU:0'):\n",
    "    history = model.fit(dataset, steps_per_epoch=train_size // batch_size,\n",
    "                    epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(texts):\n",
    "    X = np.array(tokenizer.texts_to_sequences(texts)) - 1\n",
    "    return tf.one_hot(X, max_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1, 13,  0,  2,  9,  1,  0,  2,  3, 13]], dtype=int64)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = preprocess([\"How are yo\"])\n",
    "Y_pred = model.predict_classes(X_new)\n",
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'u'"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.sequences_to_texts(Y_pred + 1)[0][-1] # 1st sentence, last char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_char(text, temperature=1):\n",
    "    X_new = preprocess([text])\n",
    "    y_proba = model.predict(X_new)[0, -1:, :]\n",
    "    rescaled_logits = tf.math.log(y_proba) / temperature\n",
    "    char_id = tf.random.categorical(rescaled_logits, num_samples=1) + 1\n",
    "    return tokenizer.sequences_to_texts(char_id.numpy())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'u'"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "next_char(\"How are yo\", temperature=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_text(text, n_chars=50, temperature=1):\n",
    "    for _ in range(n_chars):\n",
    "        text += next_char(text, temperature)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tycc ba\n",
      "doveay enerobpance, cra\n",
      "vijoevins! drazeryp\n"
     ]
    }
   ],
   "source": [
    "print(complete_text(\"t\", temperature=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stateful RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(encoded[:train_size])\n",
    "dataset = dataset.window(windows_length, shift=n_steps, drop_remainder=True)\n",
    "dataset = dataset.flat_map(lambda window: window.batch(windows_length))\n",
    "dataset = dataset.repeat().batch(1)\n",
    "dataset = dataset.map(lambda window: (window[:-1], window[1:]))\n",
    "dataset = dataset.map(lambda X_batch, y_batch:\n",
    "                                         (tf.one_hot(X_batch, depth=max_id), y_batch))\n",
    "dataset = dataset.prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "encoded_parts = np.array_split(encoded[:train_size], batch_size)\n",
    "datasets = []\n",
    "for encoded_part in encoded_parts:\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(encoded_part)\n",
    "    dataset = dataset.window(windows_length, shift=n_steps, drop_remainder=True)\n",
    "    dataset = dataset.flat_map(lambda window: window.batch(windows_length))\n",
    "    datasets.append(dataset)\n",
    "\n",
    "dataset = tf.data.Dataset.zip(tuple(datasets)).map(lambda *windows: tf.stack(windows))\n",
    "dataset = dataset.repeat().map(lambda windows: (windows[:, :-1], windows[:, 1:]))\n",
    "dataset = dataset.map(\n",
    "    lambda X_batch, Y_batch: (tf.one_hot(X_batch, depth=max_id), Y_batch))\n",
    "dataset = dataset.prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.GRU(128, return_sequences=True, stateful=True,\n",
    "                     dropout=0.2, recurrent_dropout=0.2,\n",
    "                     batch_input_shape=[batch_size, None, max_id]),\n",
    "    keras.layers.GRU(64, return_sequences=True, stateful=True,\n",
    "                     dropout=0.2, recurrent_dropout=0.2),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(max_id,\n",
    "                                                    activation=\"softmax\"))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_16 (GRU)                 (32, None, 128)           64896     \n",
      "_________________________________________________________________\n",
      "gru_17 (GRU)                 (32, None, 64)            37248     \n",
      "_________________________________________________________________\n",
      "time_distributed_12 (TimeDis (None, None, 39)          2535      \n",
      "=================================================================\n",
      "Total params: 104,679\n",
      "Trainable params: 104,679\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResetStatesCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_begin(self, epoch, logs):\n",
    "        self.model.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 52 steps\n",
      "Epoch 1/7\n",
      "52/52 [==============================] - 48s 924ms/step - loss: 3.6636\n",
      "Epoch 2/7\n",
      "52/52 [==============================] - 40s 772ms/step - loss: 3.6636\n",
      "Epoch 3/7\n",
      "52/52 [==============================] - 39s 750ms/step - loss: 3.6636\n",
      "Epoch 4/7\n",
      "52/52 [==============================] - 38s 735ms/step - loss: 3.6636\n",
      "Epoch 5/7\n",
      "52/52 [==============================] - 39s 755ms/step - loss: 3.6636\n",
      "Epoch 6/7\n",
      "52/52 [==============================] - 38s 730ms/step - loss: 3.6636\n",
      "Epoch 7/7\n",
      "52/52 [==============================] - 38s 729ms/step - loss: 3.6636\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/device:GPU:0'):\n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\")\n",
    "    steps_per_epoch = train_size // batch_size // n_steps   # Becoz shift=m_steps (train_size/(n_steps*batch_size))\n",
    "    history = model.fit(dataset, steps_per_epoch=steps_per_epoch, epochs=7,\n",
    "                        callbacks=[ResetStatesCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "stateless_model = keras.models.Sequential([\n",
    "    keras.layers.GRU(128, return_sequences=True, input_shape=[None, max_id]),\n",
    "    keras.layers.GRU(64, return_sequences=True),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(max_id,\n",
    "                                                    activation=\"softmax\"))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "stateless_model.build(tf.TensorShape([None, None, max_id]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "stateless_model.set_weights(model.get_weights())\n",
    "model = stateless_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
